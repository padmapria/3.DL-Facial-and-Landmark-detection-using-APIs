{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Background\n",
    "\n",
    "Your familyhas asked you to use AI to help them with the following problem.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: The digital photo generation\n",
    "\n",
    "Your family bought their first digital camera in the 1990s-2000s and took a lot of pictures including selfies, group photos, food, scenery etc. This year, they realized you have accumulated thousands of photos and you think that it is time you sorted them out. Obviously, it is going to be tedious to be sorting so many photos and you know that you may even make some mistakes. \n",
    "\n",
    "So you decided to write a tool that makes use of the Image Recognition engine and  Rekognition facial APIs to help you to sort the photos into different folders.\n",
    "\n",
    "This is an example of your folder structure.\n",
    "\n",
    "```\n",
    "OriginalPhotos\\\n",
    "  photo1.jpg\n",
    "  photo2.jpg\n",
    "  ...\n",
    "  \n",
    "FacesPhotos\\\n",
    "  Alice\\\n",
    "    faceofalice1.jpg\n",
    "  Max\\\n",
    "    faceofmax1.jpg\n",
    "\n",
    "SortedPhotos\\\n",
    "  ObjectsAndScenes\\\n",
    "    Car\\\n",
    "      photo1.jpg\n",
    "    Beach\n",
    "      photo2.jpg\n",
    "  People\\\n",
    "    Alice\\\n",
    "      photo1.jpg\n",
    "    Max\\\n",
    "      photo2.jpg\n",
    "    ...\n",
    "  Landmarks\\\n",
    "    EiffelTower\\\n",
    "      photo1.jpg\n",
    "    Merlion\\\n",
    "    ...\n",
    "```\n",
    "\n",
    "The \"OriginalPhotos\" folder is where you will place *all* your photos taken by you in the past. You will not store them into different sub-folders.\n",
    "\n",
    "The \"FacesPhotos\" folder contains a set of sub-folders, each named with the person's name. Within each sub-folder is one or more photos of the person you want to recognize.\n",
    "\n",
    "The \"SortedPhotos\" folder is where you will copy photos from the \"OriginalPhotos\" folder into the respective photos above automatically, with help from the Objects-and-Scene Detection and Facial Recognition APIs.\n",
    "\n",
    "In the example above, there are 2 photos in the \"OriginalPhotos\" folder. \n",
    "- photo1.jpg is a photo of Alice standing near a car.\n",
    "- photo2.jpg is a photo of Max walking with an unknown person on the beach.\n",
    "\n",
    "The \"SortedPhotos\" contains photo1.jpg copied to both the \"SortedPhotos\\People\\Alice\",  \"SortedPhotos\\ObjectsAndScenes\\Car\" and \"SortedPhotos\\Landmarks\\EiffelTower\" folders. It also contains photo2.jpg copied to both the \"SortedPhotos\\People\\Alice\" and \"SortedPhotos\\ObjectsAndScenes\\Car\" folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import Libraries\n",
    "\n",
    "Import the neccessary libaries.\n",
    "\n",
    "Use the key provided in class and remember to use your admin number as your collection id.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T05:50:19.321242Z",
     "start_time": "2020-01-18T05:50:16.005565Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "from botocore.exceptions import ClientError\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from PIL import Image, ImageDraw\n",
    "from io import BytesIO\n",
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "collectionId = '19A'\n",
    "region = 'ap-southeast-2'\n",
    "access_key = 'A'\n",
    "secret_key = 'Z'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T10:29:31.178172Z",
     "start_time": "2020-01-18T10:29:31.162171Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "googleAPIKey = \"A\"\n",
    "\n",
    "import requests \n",
    "import base64\n",
    "from botocore.exceptions import ClientError\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from PIL import Image, ImageDraw\n",
    "from io import BytesIO\n",
    "\n",
    "googleurl = \"https://vision.googleapis.com/v1/images:annotate?key=\" + googleAPIKey\n",
    "googleheaders = {'Content-Type': 'application/json'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create the client object to send request to the Amazon Web Services. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T10:29:32.422530Z",
     "start_time": "2020-01-18T10:29:32.394530Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = boto3.client('rekognition',\n",
    "    region_name = region,\n",
    "    aws_access_key_id = access_key,\n",
    "    aws_secret_access_key = secret_key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create a new collection of faces of people who you want to recognise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T11:56:12.270336Z",
     "start_time": "2020-01-18T11:56:11.157739Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection deleted.\n",
      "Collection created.\n"
     ]
    }
   ],
   "source": [
    "# Delete the collection (if it already exists)\n",
    "try:\n",
    "    client.delete_collection(CollectionId = collectionId)\n",
    "    print ('Collection deleted.')\n",
    "except ClientError as e:\n",
    "    print ('Collection deleted.')\n",
    "    \n",
    "# then we create a new collection with that same name.\n",
    "try:\n",
    "    response = client.create_collection(CollectionId = collectionId)\n",
    "    print ('Collection created.')\n",
    "except ClientError as e:\n",
    "    if e.response['Error']['Code'] == 'ResourceAlreadyExistsException':\n",
    "        print ('The collection ' + collectionId + ' already exists. Run the Python code in the Delete Collection section below.')\n",
    "    else:\n",
    "        print ('Some other error has occured.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Index Photos of 3-4 People Using Amazon Rekognition \n",
    "\n",
    "Using the small set of photos (3-4 photos per person) that you have gathered, place the pictures in individual folders. Write codes to upload the photos to Amazon to index those faces. \n",
    "\n",
    "*NOTE: You may use your personal photos, but you can also use photos of other people obtained from the internet. Each learner should have a unique set of photos from others.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T11:56:22.660443Z",
     "start_time": "2020-01-18T11:56:13.586433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing: FacesPhotos\\Kate\\faceofKate1.jpg\n",
      "Indexing: FacesPhotos\\Kate\\faceofKate2.jpg\n",
      "Indexing: FacesPhotos\\MdmLee\\faceofMdmLee1.jpg\n",
      "Indexing: FacesPhotos\\MdmLee\\faceofMdmLee2.jpg\n",
      "Indexing: FacesPhotos\\Modi\\faceofModi1.jpg\n",
      "Indexing: FacesPhotos\\Modi\\faceofModi2.jpeg\n",
      "Indexing: FacesPhotos\\Son\\faceofSon1.jpg\n",
      "Indexing: FacesPhotos\\Son\\faceofSon2.jpg\n",
      "Indexing complete.\n"
     ]
    }
   ],
   "source": [
    "# Index photographs of faces found under the FacesPhotos folder #\n",
    "files = []\n",
    "\n",
    "# loop through the files and folders under P06-data\n",
    "#\n",
    "for r, d, f in os.walk('FacesPhotos'):\n",
    "    \n",
    "    # Each folder created under data contains photos of \n",
    "    # the same person. And we will treat the folder name as\n",
    "    # an identifier for that person.\n",
    "    #\n",
    "    for personId in d:\n",
    "        \n",
    "        # Loop through the files in the data folder\n",
    "        #\n",
    "        for r1, d1, f1 in os.walk('FacesPhotos\\\\' + personId):\n",
    "            \n",
    "            # Retrieve the file name of each file\n",
    "            #\n",
    "            for file in f1:\n",
    "                \n",
    "                imageFilename = 'FacesPhotos\\\\' + personId + '\\\\' + file\n",
    "                print ('Indexing: ' + imageFilename)\n",
    "                \n",
    "                # Request Amazon to index the face found in the file.\n",
    "                #\n",
    "                with open(imageFilename, 'rb') as image:\n",
    "                    response = client.index_faces(\n",
    "                        CollectionId = collectionId, \n",
    "                        Image = {'Bytes': image.read()}, \n",
    "                        ExternalImageId = personId,\n",
    "                        MaxFaces = 1,\n",
    "                        QualityFilter = \"AUTO\",\n",
    "                        DetectionAttributes = [\"ALL\"])  \n",
    "\n",
    "print ('Indexing complete.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Copy Photos to Folder Based on Attributes and Faces Recognized\n",
    "\n",
    "Collect a set of about 20 photos and place them into a folder and send each photo to either:\n",
    "- Amazon Rekognition Object-and-Scene Detection OR \n",
    "- Google's Cloud Vision API for Object-and-Scene and Landmark Detection\n",
    "for recognition\n",
    "\n",
    "If the results shows that there is a Human/Person/Man:\n",
    "- Send the pictures to Amazon Facial Recognition.\n",
    "\n",
    "Using the attributes returned from Object-and-Scene Detection API (only those whose confidence > 95%), duplicate the picture to the relevant folders.\n",
    "\n",
    "Using recognized face match result returned from the Facial Recognition API (face match threshold > 90%), duplicate the picture to the relevant folders.\n",
    "\n",
    "The cell below shows an example skeleton of how your tool should be coded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-18T12:51:07.011987Z",
     "start_time": "2020-01-18T12:51:06.999980Z"
    }
   },
   "outputs": [],
   "source": [
    "# Codes below shows how to copy a file from one folder to another \n",
    "#\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# This function copies a file provided in the original file path\n",
    "# to the destination folder.\n",
    "#\n",
    "# If the destination folder does not exist, it will create it.\n",
    "#\n",
    "def copy(original_file_path, destination_folder_path):\n",
    "    if not os.path.exists(destination_folder_path):\n",
    "        os.makedirs(destination_folder_path)\n",
    "    shutil.copy(original_file_path,  destination_folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-01-18T12:51:08.072Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Picture To Process: OriginalPhotos\\photo01.jpeg\n",
      "ObjectsAndScenes 92.09 Man\n",
      "Face Recognized  Modi\n",
      "Face Recognized  Modi\n",
      "ObjectsAndScenes 89.30 Man\n",
      "Face Recognized  Modi\n",
      "Face Recognized  Modi\n",
      "ObjectsAndScenes 83.89 Coat\n",
      "ObjectsAndScenes 80.54 Pants\n",
      "\n",
      "Picture To Process: OriginalPhotos\\photo02.jpg\n",
      "Landmarks 88.81 Liberty Island\n",
      "Landmarks 88.29 Margaret Pace Park\n",
      "Landmarks 80.83 Statue of Liberty National Monument\n",
      "ObjectsAndScenes 93.75 Glasses\n",
      "ObjectsAndScenes 85.57 Person\n",
      "Face Recognized  Son\n",
      "Face Recognized  MdmLee\n",
      "ObjectsAndScenes 82.30 Person\n",
      "Face Recognized  Son\n",
      "Face Recognized  MdmLee\n",
      "\n",
      "Picture To Process: OriginalPhotos\\photo03.jpg\n",
      "Landmarks 86.32 Niterói Contemporary Art Museum\n",
      "Landmarks 82.64 Niterói Contemporary Art Museum\n",
      "ObjectsAndScenes 84.68 Person\n",
      "Face Recognized  MdmLee\n",
      "ObjectsAndScenes 83.24 Woman\n",
      "Face Recognized  MdmLee\n",
      "\n",
      "Picture To Process: OriginalPhotos\\photo04.jpg\n",
      "Landmarks 81.47 Dancing House\n",
      "ObjectsAndScenes 92.41 Glasses\n",
      "ObjectsAndScenes 81.57 Person\n",
      "Face Recognized  Son\n",
      "Face Recognized  MdmLee\n",
      "\n",
      "Picture To Process: OriginalPhotos\\photo05.jpg\n",
      "Landmarks 83.71 Taj Mahal\n",
      "ObjectsAndScenes 92.19 Woman\n",
      "Face Recognized  Kate\n",
      "ObjectsAndScenes 91.37 Man\n",
      "Face Recognized  Kate\n",
      "ObjectsAndScenes 87.19 Dress\n",
      "\n",
      "Picture To Process: OriginalPhotos\\photo06.jpg\n",
      "ObjectsAndScenes 92.09 Man\n",
      "Face Recognized  Modi\n",
      "ObjectsAndScenes 91.79 Man\n",
      "Face Recognized  Modi\n",
      "ObjectsAndScenes 90.61 Man\n",
      "Face Recognized  Modi\n",
      "ObjectsAndScenes 90.46 Man\n",
      "Face Recognized  Modi\n",
      "\n",
      "Picture To Process: OriginalPhotos\\photo07.jpg\n",
      "Landmarks 85.77 Taj Mahal\n",
      "Landmarks 81.91 Taj Mahal Garden\n",
      "ObjectsAndScenes 87.17 Woman\n",
      "ObjectsAndScenes 86.84 Man\n",
      "ObjectsAndScenes 86.43 Building\n",
      "\n",
      "Picture To Process: OriginalPhotos\\photo08.jpg\n",
      "ObjectsAndScenes 88.73 Hat\n",
      "ObjectsAndScenes 88.32 Hat\n",
      "ObjectsAndScenes 87.07 Woman\n",
      "Face Recognized  Kate\n",
      "ObjectsAndScenes 83.31 Man\n",
      "Face Recognized  Kate\n",
      "\n",
      "Picture To Process: OriginalPhotos\\photo09.jpg\n",
      "ObjectsAndScenes 89.67 Man\n",
      "Face Recognized  Modi\n",
      "ObjectsAndScenes 87.44 Person\n",
      "Face Recognized  Modi\n",
      "ObjectsAndScenes 87.33 Person\n",
      "Face Recognized  Modi\n",
      "ObjectsAndScenes 85.92 Person\n",
      "Face Recognized  Modi\n",
      "ObjectsAndScenes 84.56 Person\n",
      "Face Recognized  Modi\n",
      "\n",
      "Picture To Process: OriginalPhotos\\photo10.jpeg\n",
      "ObjectsAndScenes 91.30 Person\n",
      "Face Recognized  Kate\n",
      "ObjectsAndScenes 88.93 Shoe\n",
      "ObjectsAndScenes 88.57 Footwear\n",
      "ObjectsAndScenes 86.68 Person\n",
      "Face Recognized  Kate\n",
      "ObjectsAndScenes 86.39 Person\n",
      "Face Recognized  Kate\n",
      "ObjectsAndScenes 86.39 Person\n",
      "Face Recognized  Kate\n",
      "ObjectsAndScenes 86.03 Person\n",
      "Face Recognized  Kate\n",
      "ObjectsAndScenes 84.78 Dress\n",
      "ObjectsAndScenes 84.57 Shoe\n",
      "ObjectsAndScenes 83.35 Woman\n",
      "Face Recognized  Kate\n",
      "\n",
      "Picture To Process: OriginalPhotos\\photo11.jpeg\n",
      "Landmarks 82.39 Kedarnath Temple\n",
      "ObjectsAndScenes 89.89 Man\n",
      "Face Recognized  Modi\n",
      "Face Recognized  Modi\n",
      "ObjectsAndScenes 87.78 Man\n",
      "Face Recognized  Modi\n",
      "Face Recognized  Modi\n",
      "ObjectsAndScenes 87.33 Man\n",
      "Face Recognized  Modi\n",
      "Face Recognized  Modi\n",
      "ObjectsAndScenes 87.23 Man\n",
      "Face Recognized  Modi\n",
      "Face Recognized  Modi\n",
      "\n",
      "Picture To Process: OriginalPhotos\\photo12.jpg\n",
      "ObjectsAndScenes 88.18 Sunglasses\n",
      "ObjectsAndScenes 87.22 Woman\n",
      "Face Recognized  Kate\n",
      "ObjectsAndScenes 86.85 Man\n",
      "Face Recognized  Kate\n",
      "ObjectsAndScenes 82.97 Top\n",
      "\n",
      "Picture To Process: OriginalPhotos\\photo13.jpeg\n",
      "ObjectsAndScenes 88.31 Man\n",
      "Face Recognized  Modi\n",
      "ObjectsAndScenes 87.41 Man\n",
      "Face Recognized  Modi\n",
      "ObjectsAndScenes 84.16 Pants\n",
      "\n",
      "Picture To Process: OriginalPhotos\\photo14.jpg\n",
      "Landmarks 86.99 Harmandir Sahib\n",
      "ObjectsAndScenes 88.58 Man\n",
      "Face Recognized  Modi\n",
      "ObjectsAndScenes 87.66 Building\n",
      "\n",
      "Picture To Process: OriginalPhotos\\photo15.jpg\n",
      "Landmarks 87.79 Quick Angoulême CV\n",
      "ObjectsAndScenes 94.04 Pants\n",
      "ObjectsAndScenes 89.80 Man\n",
      "Face Recognized  Kate\n",
      "ObjectsAndScenes 87.39 Dress\n",
      "ObjectsAndScenes 86.99 Woman\n",
      "Face Recognized  Kate\n",
      "ObjectsAndScenes 84.02 Coat\n",
      "\n",
      "Picture To Process: OriginalPhotos\\photo16.jpg\n",
      "ObjectsAndScenes 92.49 Man\n",
      "Face Recognized  Modi\n",
      "ObjectsAndScenes 84.65 Flag\n",
      "\n",
      "Picture To Process: OriginalPhotos\\photo17.jpg\n",
      "ObjectsAndScenes 92.58 Glasses\n",
      "ObjectsAndScenes 87.11 Person\n",
      "Face Recognized  Son\n",
      "Face Recognized  MdmLee\n",
      "ObjectsAndScenes 83.75 Person\n",
      "Face Recognized  Son\n",
      "Face Recognized  MdmLee\n",
      "ObjectsAndScenes 83.58 Hat\n",
      "ObjectsAndScenes 82.08 Person\n",
      "Face Recognized  Son\n",
      "Face Recognized  MdmLee\n",
      "\n",
      "Picture To Process: OriginalPhotos\\photo18.jpg\n",
      "ObjectsAndScenes 91.96 Glasses\n",
      "ObjectsAndScenes 90.72 Person\n",
      "Face Recognized  Son\n",
      "ObjectsAndScenes 86.77 Person\n",
      "Face Recognized  Son\n",
      "\n",
      "Picture To Process: OriginalPhotos\\photo19.jpg\n",
      "ObjectsAndScenes 87.91 Man\n",
      "Face Recognized  Modi\n",
      "Face Recognized  Modi\n",
      "ObjectsAndScenes 86.46 Man\n",
      "Face Recognized  Modi\n",
      "Face Recognized  Modi\n",
      "ObjectsAndScenes 84.97 Man\n",
      "Face Recognized  Modi\n"
     ]
    }
   ],
   "source": [
    "# Loop through the files in your OriginalPhotos folder using google\n",
    "for r, d, files in os.walk('OriginalPhotos'):\n",
    "\n",
    "    for filename in files:\n",
    "        \n",
    "        # Load the image bytes that we will use to send to Amazon later.\n",
    "        photo = 'OriginalPhotos\\\\' + filename \n",
    "       \n",
    "        print(\"\\nPicture To Process: %s\" % photo)\n",
    "        # Load the actual image that can be used to crop out the faces later\n",
    "        image = Image.open(photo)\n",
    "        stream = io.BytesIO()\n",
    "        image.save(stream,format=\"JPEG\")\n",
    "        image_binary = stream.getvalue()\n",
    "\n",
    "        # Send the image bytes to the Object-and-Scene (and Landmark Detection for additional marks) API\n",
    "        # https://docs.aws.amazon.com/rekognition/latest/dg/images-bytes.html#w696aac18b7c19c16b4b2b3\n",
    "        \n",
    "        # ToDo: Construct the data to Google\n",
    "        #\n",
    "        data = {\n",
    "            'requests': \n",
    "            [\n",
    "                {\n",
    "                    'image': { 'content': base64.b64encode(image_binary).decode(\"utf-8\") },\n",
    "                    'features': [ { 'type': 'OBJECT_LOCALIZATION' }, \n",
    "                                 { 'type': 'LABEL_DETECTION' },\n",
    "                                 { 'type': 'LANDMARK_DETECTION' }]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        # ToDo: Send the image data to Google to recognize\n",
    "        #\n",
    "        r = requests.post(url = googleurl, headers = googleheaders, json = data) \n",
    "\n",
    "        # Check and display the results\n",
    "        if r.status_code == 200:\n",
    "            result = r.json()\n",
    "\n",
    "            #print (result)\n",
    "\n",
    "            # ToDo: Write a for-loop to loop through all the 'responses'.\n",
    "            #\n",
    "            for response in result['responses']:\n",
    "\n",
    "                # Do a sanity check, in case the key doesn't exist in the dictionary\n",
    "                #\n",
    "                if 'landmarkAnnotations' in response:\n",
    "                    for annotation in response['landmarkAnnotations']:\n",
    "                        if float(annotation['score']) * 100 > 80.0:\n",
    "                            print(\"Landmarks %4.2f %s\" % (annotation['score'] * 100, annotation['description']))\n",
    "                            landMarks(photo,annotation[\"description\"])\n",
    "                            copy(\"OriginalPhotos\\\\\" + filename, \"SortedPhotos\\\\LandMarks\\\\\" + annotation['description'])\n",
    "                            \n",
    "\n",
    "                # Do a sanity check, in case the key doesn't exist in the dictionary\n",
    "                #\n",
    "                if 'localizedObjectAnnotations' in response:\n",
    "                    for annotation in response['localizedObjectAnnotations']:\n",
    "                        \n",
    "                        if float(annotation['score']) * 100 > 80.0:\n",
    "                            print(\"ObjectsAndScenes %4.2f %s\" % (annotation['score'] * 100, annotation['name']))\n",
    "                            \n",
    "                            if(annotation['name']=='Person' or annotation['name']=='Woman' or annotation['name']=='Man'):\n",
    "\n",
    "                                # Detect faces in the photo\n",
    "                                response1 = client.detect_faces(\n",
    "                                Image={'Bytes':image_binary}                                        \n",
    "                                    )\n",
    "\n",
    "                                all_faces=response1['FaceDetails']\n",
    "                                # Initialize list object\n",
    "                                boxes = []\n",
    "\n",
    "                                # Get image diameters\n",
    "                                image_width = image.size[0]\n",
    "                                image_height = image.size[1]\n",
    "\n",
    "                                # Loop through all detected faces in the photo\n",
    "                                for face in all_faces:\n",
    "                                    # Crop out the faces from the photo\n",
    "                                    box=face['BoundingBox']\n",
    "                                    x1 = int(box['Left'] * image_width) * 0.9\n",
    "                                    y1 = int(box['Top'] * image_height) * 0.9\n",
    "                                    x2 = int(box['Left'] * image_width + box['Width'] * image_width) * 1.10\n",
    "                                    y2 = int(box['Top'] * image_height + box['Height']  * image_height) * 1.10\n",
    "                                    image_crop = image.crop((x1,y1,x2,y2))\n",
    "\n",
    "                                    stream = io.BytesIO()\n",
    "                                    image_crop.save(stream,format=\"JPEG\")\n",
    "                                    image_crop_binary = stream.getvalue()\n",
    "\n",
    "                                    # Send the cropped photo to Amazon Facial Recognition API\n",
    "                                    response2 = client.search_faces_by_image(\n",
    "                                            CollectionId=collectionId,\n",
    "                                            Image={'Bytes':image_crop_binary},\n",
    "                                            MaxFaces = 5,\n",
    "                                            FaceMatchThreshold = 90\n",
    "                                            )\n",
    "\n",
    "                                    # Identify the known faces from the API and copy the photo to the appropriate folders\n",
    "                                    # under your SortedPhotos folder\n",
    "                                    #\n",
    "                                    if(len(response2['FaceMatches']) > 0):\n",
    "                                        faceMatch = response2[\"FaceMatches\"][0]\n",
    "                                        person_name=faceMatch['Face']['ExternalImageId']\n",
    "                                        print(\"Face Recognized \", person_name)\n",
    "                                        copy(\"OriginalPhotos\\\\\" + filename, \"SortedPhotos\\\\People\\\\\" + person_name)                                            \n",
    "\n",
    "                            else:\n",
    "                                copy(\"OriginalPhotos\\\\\" + filename, \"SortedPhotos\\\\ObjectsAndScenes\\\\\" + annotation['name'])\n",
    "                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Submission\n",
    "\n",
    "### Submission Requirements\n",
    "\n",
    "Please submit the following:\n",
    "\n",
    "1. Entire folder structure containing photos of 3-4 people used to index faces\n",
    "2. Entire folder structure containing 20 photos of the 3-4 people in different scenes and backgrounds\n",
    "3. A copy of this Jupyter Notebook containing your work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Codes on how to copy files from one directory to another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-27T21:02:35.436264Z",
     "start_time": "2019-12-27T21:02:35.427267Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# The following is an example of how to use the copy function\\n#\\nfilename = \\'rose.jpg\\'\\n\\n# Note that in Python strings, the backslash \"\" is a special character, also called the \"escape\" character. \\n# It is used in representing certain whitespace characters: \\n# \"\\t\" is a tab, \"\\n\" is a newline, and \"\\r\" is a carriage return \\n#\\n\\noriginal_folder =  PureWindowsPath(\"C:\\\\TMP\\\\old_folder\") \\nnew_folder = PureWindowsPath(\"C:\\\\TMP\\\\new_folder\")\\noriginal_file = original_folder.joinpath(filename)\\n\\ncopy(original_file, new_folder)\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Codes below shows how to copy a file from one folder to another \n",
    "#\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# This function copies a file provided in the original file path\n",
    "# to the destination folder.\n",
    "#\n",
    "# If the destination folder does not exist, it will create it.\n",
    "#\n",
    "def copy(original_file_path, destination_folder_path):\n",
    "    if not os.path.exists(destination_folder_path):\n",
    "        os.makedirs(destination_folder_path)\n",
    "    shutil.copy(original_file,  destination_folder_path)\n",
    "\n",
    "'''\n",
    "# The following is an example of how to use the copy function\n",
    "#\n",
    "filename = 'rose.jpg'\n",
    "\n",
    "# Note that in Python strings, the backslash \"\\\" is a special character, also called the \"escape\" character. \n",
    "# It is used in representing certain whitespace characters: \n",
    "# \"\\t\" is a tab, \"\\n\" is a newline, and \"\\r\" is a carriage return \n",
    "#\n",
    "\n",
    "original_folder =  PureWindowsPath(\"C:\\\\TMP\\\\old_folder\") \n",
    "new_folder = PureWindowsPath(\"C:\\TMP\\\\new_folder\")\n",
    "original_file = original_folder.joinpath(filename)\n",
    "\n",
    "copy(original_file, new_folder)\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
